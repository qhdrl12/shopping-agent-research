# app.py
"""
AI ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ ì›¹ ì¸í„°í˜ì´ìŠ¤

ì´ ëª¨ë“ˆì€ Streamlitì„ ì‚¬ìš©í•˜ì—¬ AI ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
LangChain/LangGraph ì—ì´ì „íŠ¸ì™€ FireCrawl ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆì˜ì— ì‘ë‹µí•˜ë©°,
LangGraphì˜ checkpoint_nsë¥¼ í™œìš©í•œ ì •í™•í•œ ë„êµ¬ ì¶”ì  ë° ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
- ë„êµ¬ ì‹¤í–‰ ìƒíƒœ ì¶”ì  ë° ì‹œê°í™”
- ê·¸ë£¹ ë‹¨ìœ„ ì—ëŸ¬ ì²˜ë¦¬ (checkpoint_ns ê¸°ë°˜)
- ë„êµ¬ ì‹¤í–‰ ì‹œê°„ ë° ìƒì„¸ ì •ë³´ í‘œì‹œ
"""

import streamlit as st
import asyncio
import json
import traceback
import uuid

from datetime import datetime
from dotenv import load_dotenv
from langchain_core.messages import ToolMessage, AIMessage
from typing import Dict, Any, List, Optional, Set, Tuple
# from src.agent.enhanced_shopping_agent import build_enhanced_agent as build_agent
from src.utils.local_prompt_manager import LocalPromptManager
from src.agent.shopping_react_agent import build_agent

load_dotenv()


# =============================================================================
# Streamlit ì•± ì„¤ì • ë° ì´ˆê¸°í™”
# =============================================================================

st.set_page_config(
    page_title="ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸", 
    page_icon="ğŸ›ï¸", 
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” - Streamlitì˜ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ
if 'agent' not in st.session_state:
    st.session_state.agent = None  # LangChain ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤
if 'messages' not in st.session_state:
    st.session_state.messages = []  # ì±„íŒ… ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬
if 'history' not in st.session_state:
    st.session_state.history = []  # LangChain ëŒ€í™” íˆìŠ¤í† ë¦¬

# í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'prompt_manager' not in st.session_state:
    st.session_state.prompt_manager = LocalPromptManager()
if 'active_prompt_name' not in st.session_state:
    st.session_state.active_prompt_name = 'default'
if 'prompt_edit_mode' not in st.session_state:
    st.session_state.prompt_edit_mode = False
if 'show_prompt_manager' not in st.session_state:
    st.session_state.show_prompt_manager = False
if 'current_editing_prompt' not in st.session_state:
    st.session_state.current_editing_prompt = None
if 'show_new_prompt_form' not in st.session_state:
    st.session_state.show_new_prompt_form = False


# =============================================================================
# ë„êµ¬ ì‹¤í–‰ ì¶”ì  í´ë˜ìŠ¤
# =============================================================================

class ToolExecutionTracker:
    """
    LangGraph ë„êµ¬ ì‹¤í–‰ì„ ì¶”ì í•˜ê³  ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” LangGraphì˜ checkpoint_ns ì‹œìŠ¤í…œì„ í™œìš©í•˜ì—¬ ë„êµ¬ ê·¸ë£¹ì„ ì •í™•íˆ ì¶”ì í•˜ê³ ,
    ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ê·¸ë£¹ ë‚´ ëª¨ë“  ë„êµ¬ì— ì¼ê´€ëœ ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    ì£¼ìš” êµ¬ì„± ìš”ì†Œ:
    - tool_calls: ê°œë³„ ë„êµ¬ ì‹¤í–‰ ì •ë³´ ì €ì¥ (run_id ê¸°ë°˜)
    - tools_groups: ë„êµ¬ ê·¸ë£¹ ì¶”ì  (checkpoint_ns ê¸°ë°˜)
    - completed_tools: ì™„ë£Œëœ ë„êµ¬ ì¶”ì 
    """
    
    def __init__(self):
        """ì¶”ì ê¸° ì´ˆê¸°í™”"""
        # ê°œë³„ ë„êµ¬ ì‹¤í–‰ ì •ë³´ë¥¼ run_idë¡œ ì¶”ì 
        # ê° ë„êµ¬ì˜ ì‹œì‘ì‹œê°„, ì¢…ë£Œì‹œê°„, ì…ë ¥, ì¶œë ¥, ì—ëŸ¬ ìƒíƒœ ë“±ì„ ì €ì¥
        self.tool_calls: Dict[str, Dict[str, Any]] = {}
        
        # LangGraphì˜ checkpoint_nsë¡œ ë„êµ¬ ê·¸ë£¹ì„ ì¶”ì 
        # í˜•íƒœ: {"tools:uuid": {run_id1, run_id2, run_id3}}
        # ê°™ì€ ìš”ì²­ì—ì„œ ì‹¤í–‰ë˜ëŠ” ì—¬ëŸ¬ ë„êµ¬ë“¤ì´ ë™ì¼í•œ namespaceë¥¼ ê³µìœ 
        self.tools_groups: Dict[str, Set[str]] = {}
        
        # ì™„ë£Œëœ ë„êµ¬ë“¤ì˜ run_id ì§‘í•©
        # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€ ë° ìƒíƒœ ì¶”ì ìš©
        self.completed_tools: Set[str] = set()
    
    def extract_tools_namespace(self, event: Dict[str, Any]) -> Optional[str]:
        """
        LangGraph ì´ë²¤íŠ¸ì—ì„œ tools namespaceë¥¼ ì¶”ì¶œ
        
        LangGraphëŠ” ê´€ë ¨ëœ ë„êµ¬ë“¤ì„ 'tools:uuid' í˜•íƒœì˜ namespaceë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.
        ì´ë¥¼ í†µí•´ ë™ì¼í•œ ìš”ì²­ì—ì„œ ì‹¤í–‰ë˜ëŠ” ì—¬ëŸ¬ ë„êµ¬ë“¤ì„ í•˜ë‚˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        Args:
            event: LangGraph ì´ë²¤íŠ¸ ê°ì²´
            
        Returns:
            tools namespace ë¬¸ìì—´ ë˜ëŠ” None
        """
        metadata = event.get('metadata', {})
        checkpoint_ns = metadata.get('langgraph_checkpoint_ns', '')
        
        # 'tools:'ë¡œ ì‹œì‘í•˜ëŠ” namespaceë§Œ ìœ íš¨í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
        if checkpoint_ns and checkpoint_ns.startswith('tools:'):
            return checkpoint_ns
        return None
    
    def start_tool_execution(
        self, 
        run_id: str, 
        tool_name: str, 
        input_data: Any, 
        event: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ë„êµ¬ ì‹¤í–‰ ì‹œì‘ì„ ì¶”ì  ë° ë“±ë¡
        
        ìƒˆë¡œìš´ ë„êµ¬ ì‹¤í–‰ì´ ì‹œì‘ë  ë•Œ í˜¸ì¶œë˜ë©°, ë„êµ¬ì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ì„¤ì •í•˜ê³ 
        í•´ë‹¹ ë„êµ¬ë¥¼ ì ì ˆí•œ ê·¸ë£¹ì— ë°°ì •í•©ë‹ˆë‹¤.
        
        Args:
            run_id: ë„êµ¬ ì‹¤í–‰ì˜ ê³ ìœ  ì‹ë³„ì
            tool_name: ì‹¤í–‰ë˜ëŠ” ë„êµ¬ì˜ ì´ë¦„
            input_data: ë„êµ¬ì— ì „ë‹¬ë˜ëŠ” ì…ë ¥ ë°ì´í„°
            event: LangGraph ì´ë²¤íŠ¸ ê°ì²´
            
        Returns:
            ìƒì„±ëœ ë„êµ¬ í˜¸ì¶œ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        tools_namespace = self.extract_tools_namespace(event)
        
        # ë„êµ¬ ì‹¤í–‰ ì •ë³´ êµ¬ì¡°ì²´ ìƒì„±
        call_data = {
            "run_id": run_id,
            "name": tool_name,
            "input": input_data,
            "output": None,
            "finished": False,
            "error": None,
            "start_time": asyncio.get_event_loop().time(),
            "tools_namespace": tools_namespace,
            "end_time": None
        }
        
        # run_idë¡œ ë„êµ¬ ì •ë³´ ì €ì¥
        self.tool_calls[run_id] = call_data
        
        # tools ê·¸ë£¹ì— ë„êµ¬ ì¶”ê°€
        # ê°™ì€ namespaceì˜ ë„êµ¬ë“¤ì€ í•¨ê»˜ ê´€ë¦¬ë¨
        if tools_namespace:
            if tools_namespace not in self.tools_groups:
                self.tools_groups[tools_namespace] = set()
            self.tools_groups[tools_namespace].add(run_id)
        
        return call_data
    
    def finish_tool_execution(
        self, 
        run_id: str, 
        output: Any, 
    ) -> Optional[Dict[str, Any]]:
        """
        ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ ì²˜ë¦¬
        
        ë„êµ¬ ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆì„ ë•Œ í˜¸ì¶œë˜ë©°, ê²°ê³¼ë¥¼ ì €ì¥í•˜ê³  ì—ëŸ¬ ìƒíƒœë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.
        Noneì´ë‚˜ ë¹ˆ ê²°ê³¼ì˜ ê²½ìš° ì„ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ì—¬ ë‚˜ì¤‘ì— ë” êµ¬ì²´ì ì¸
        ì—ëŸ¬ë¡œ ì—…ë°ì´íŠ¸ë  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
        
        Args:
            run_id: ì™„ë£Œëœ ë„êµ¬ì˜ ì‹¤í–‰ ID
            output: ë„êµ¬ì˜ ì‹¤í–‰ ê²°ê³¼
            event: LangGraph ì´ë²¤íŠ¸ ê°ì²´
            
        Returns:
            ì—…ë°ì´íŠ¸ëœ ë„êµ¬ í˜¸ì¶œ ë°ì´í„° ë˜ëŠ” None
        """
        if run_id not in self.tool_calls:
            return None
            
        call_data = self.tool_calls[run_id]
        call_data["output"] = output
        call_data["finished"] = True
        call_data["end_time"] = asyncio.get_event_loop().time()
        
        # ì™„ë£Œëœ ë„êµ¬ë¡œ ë§ˆí‚¹
        self.completed_tools.add(run_id)
        
        # ê²°ê³¼ ìƒíƒœ ë¶„ì„ ë° ì—ëŸ¬ ì²˜ë¦¬
        self._analyze_output_and_set_error(call_data, output)
        
        return call_data
    
    def _analyze_output_and_set_error(self, call_data: Dict[str, Any], output: Any) -> None:
        """
        ë„êµ¬ ì¶œë ¥ì„ ë¶„ì„í•˜ì—¬ ì—ëŸ¬ ìƒíƒœ ì„¤ì •
        
        ë„êµ¬ì˜ ì¶œë ¥ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì„±ê³µ/ì‹¤íŒ¨ë¥¼ íŒë‹¨í•˜ê³ , ì‹¤íŒ¨ì¸ ê²½ìš°
        ì ì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        
        Args:
            call_data: ë„êµ¬ í˜¸ì¶œ ë°ì´í„°
            output: ë„êµ¬ ì¶œë ¥
        """
        if output is None:
            # None ê²°ê³¼ëŠ” ì‹¤í–‰ ì‹¤íŒ¨ë¡œ ê°„ì£¼
            call_data["error"] = "ë„êµ¬ê°€ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            call_data["output"] = f"ToolException: {call_data['error']}"
            call_data["_is_placeholder_error"] = True
            
        elif isinstance(output, str):
            if not output.strip():
                # ë¹ˆ ë¬¸ìì—´ë„ ì‹¤íŒ¨ë¡œ ê°„ì£¼
                call_data["error"] = "ë„êµ¬ê°€ ë¹ˆ ê²°ê³¼ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤."
                call_data["output"] = f"ToolException: {call_data['error']}"
                call_data["_is_placeholder_error"] = True
            elif self._is_error_string(output):
                # ì—ëŸ¬ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ìì—´
                call_data["error"] = output
                call_data["_is_placeholder_error"] = False
                
        elif isinstance(output, (dict, list)) and len(output) == 0:
            # ë¹ˆ ë”•ì…”ë„ˆë¦¬ë‚˜ ë¦¬ìŠ¤íŠ¸ë„ ì‹¤íŒ¨ë¡œ ê°„ì£¼
            call_data["error"] = "ë„êµ¬ê°€ ë¹ˆ ê²°ê³¼ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤."
            call_data["output"] = f"ToolException: {call_data['error']}"
            call_data["_is_placeholder_error"] = True
    
    def _is_error_string(self, output: str) -> bool:
        """ë¬¸ìì—´ì´ ì—ëŸ¬ ë©”ì‹œì§€ì¸ì§€ íŒë‹¨"""
        error_keywords = ['error', 'exception', 'failed', 'timeout', 'fail']
        return any(keyword in output.lower() for keyword in error_keywords)
    
    def handle_group_error(self, error_event: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        ë„êµ¬ ê·¸ë£¹ ì „ì²´ì— ëŒ€í•œ ì—ëŸ¬ ì²˜ë¦¬
        
        LangGraphì—ì„œ on_chain_stream ì´ë²¤íŠ¸ë¥¼ í†µí•´ ì „ë‹¬ë˜ëŠ” ê·¸ë£¹ ë ˆë²¨ ì—ëŸ¬ë¥¼
        ì²˜ë¦¬í•©ë‹ˆë‹¤. checkpoint_nsë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ ê·¸ë£¹ì˜ ëª¨ë“  ë„êµ¬ì— ë™ì¼í•œ
        ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
        
        Args:
            error_event: ì—ëŸ¬ ì´ë²¤íŠ¸ ê°ì²´
            
        Returns:
            ì—…ë°ì´íŠ¸ëœ ë„êµ¬ í˜¸ì¶œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        tools_namespace = self.extract_tools_namespace(error_event)
        updated_calls = []
        
        if not tools_namespace or tools_namespace not in self.tools_groups:
            return updated_calls
        
        # ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ
        error_message = self._extract_error_message(error_event)
        
        # í•´ë‹¹ ê·¸ë£¹ì˜ ëª¨ë“  ë„êµ¬ì— ì—ëŸ¬ ì ìš©
        for run_id in self.tools_groups[tools_namespace].copy():
            if run_id in self.tool_calls:
                call_data = self.tool_calls[run_id]
                
                # ì—ëŸ¬ ì •ë³´ ì—…ë°ì´íŠ¸
                call_data["output"] = error_message
                call_data["error"] = error_message
                call_data["finished"] = True
                
                if not call_data.get("end_time"):
                    call_data["end_time"] = asyncio.get_event_loop().time()
                
                # self.completed_tools.add(run_id)
                updated_calls.append(call_data)
        
        return updated_calls
    
    def _extract_error_message(self, error_event: Dict[str, Any]) -> str:
        """
        ì—ëŸ¬ ì´ë²¤íŠ¸ì—ì„œ êµ¬ì²´ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ
        
        Args:
            error_event: ì—ëŸ¬ ì´ë²¤íŠ¸ ê°ì²´
            
        Returns:
            ì¶”ì¶œëœ ì—ëŸ¬ ë©”ì‹œì§€
        """
        # ê¸°ë³¸ ì—ëŸ¬ ë©”ì‹œì§€
        default_message = "ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        
        chunk = error_event.get("data", {}).get("chunk", {})
        if not isinstance(chunk, dict):
            return default_message
        
        messages = chunk.get("messages", [])
        for msg in messages:
            if hasattr(msg, 'content') and msg.content:
                return str(msg.content)
        
        return default_message
    
    def handle_unfinished_tools(self, timeout_seconds: float = 5.0) -> List[Dict[str, Any]]:
        """
        ë¯¸ì™„ë£Œ ë„êµ¬ë“¤ì„ íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
        
        ìŠ¤íŠ¸ë¦¼ì´ ì¢…ë£Œë˜ì—ˆì§€ë§Œ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì€ ë„êµ¬ë“¤ì„ ì°¾ì•„ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ
        ì²˜ë¦¬í•©ë‹ˆë‹¤. ì´ëŠ” ì˜ˆìƒì¹˜ ëª»í•œ ìƒí™©ì—ì„œ UIê°€ ë¬´í•œ ëŒ€ê¸°í•˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.
        
        Args:
            timeout_seconds: íƒ€ì„ì•„ì›ƒ ê¸°ì¤€ ì‹œê°„ (ì´ˆ)
            
        Returns:
            íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ëœ ë„êµ¬ í˜¸ì¶œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        unfinished = []
        current_time = asyncio.get_event_loop().time()
        
        for call_data in self.tool_calls.values():
            if call_data["finished"] or call_data["run_id"] in self.completed_tools:
                continue
                
            execution_time = current_time - call_data["start_time"]
            
            # íƒ€ì„ì•„ì›ƒ ë©”ì‹œì§€ ì„¤ì •
            if execution_time > timeout_seconds:
                call_data["output"] = f"ToolException: ë„êµ¬ ì‹¤í–‰ íƒ€ì„ì•„ì›ƒ ({execution_time:.1f}ì´ˆ)"
                call_data["error"] = f"ë„êµ¬ ì‹¤í–‰ì´ {timeout_seconds}ì´ˆë¥¼ ì´ˆê³¼í•˜ì—¬ íƒ€ì„ì•„ì›ƒë˜ì—ˆìŠµë‹ˆë‹¤."
            else:
                call_data["output"] = "ToolException: ë„êµ¬ ì‹¤í–‰ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                call_data["error"] = "ë„êµ¬ ì‹¤í–‰ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
            call_data["finished"] = True
            call_data["end_time"] = current_time
            self.completed_tools.add(call_data["run_id"])
            unfinished.append(call_data)
        
        return unfinished
    
    def get_execution_summary(self) -> Dict[str, Any]:
        """
        ì‹¤í–‰ ìš”ì•½ ì •ë³´ ë°˜í™˜ (ë””ë²„ê¹… ë° ëª¨ë‹ˆí„°ë§ìš©)
        
        Returns:
            ì‹¤í–‰ í†µê³„ ë° ìƒíƒœ ì •ë³´
        """
        return {
            "total_tools": len(self.tool_calls),
            "completed_tools": len(self.completed_tools),
            "tools_groups": {ns: list(run_ids) for ns, run_ids in self.tools_groups.items()},
            "execution_times": {
                run_id: call_data.get("end_time", 0) - call_data["start_time"]
                for run_id, call_data in self.tool_calls.items()
                if call_data.get("end_time")
            }
        }


# =============================================================================
# ì—ì´ì „íŠ¸ ê´€ë¦¬ í•¨ìˆ˜
# =============================================================================

async def initialize_agent():
    """
    LangChain ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    
    ì—ì´ì „íŠ¸ê°€ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ build_agent()ë¥¼ í˜¸ì¶œí•˜ì—¬
    ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•©ë‹ˆë‹¤.
    
    ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€:
    - ì„¸ì…˜ ìƒíƒœë¥¼ í™•ì¸í•˜ì—¬ ì´ë¯¸ ì´ˆê¸°í™”ëœ ê²½ìš° ì¬ì‚¬ìš©
    - MCP ì„œë²„ì˜ ì¤‘ë³µ ì‹¤í–‰ì„ ë°©ì§€í•˜ì—¬ ë¦¬ì†ŒìŠ¤ ì ˆì•½
    """
    if st.session_state.agent is None:
        with st.spinner("ğŸ”§ AI ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì¤€ë¹„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ì„ì‹œ í”„ë¡¬í”„íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
                # if hasattr(st.session_state, 'temp_prompts'):
                #     # ì„ì‹œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•´ì„œ ì—ì´ì „íŠ¸ ë¹Œë“œ
                #     from src.agent.enhanced_shopping_agent import EnhancedShoppingAgent
                #     from src.config.agent_config import get_config
                    
                #     config = get_config("credit_saving")
                #     temp_agent = EnhancedShoppingAgent(config, st.session_state.active_prompt_name)
                    
                #     # ì„ì‹œ í”„ë¡¬í”„íŠ¸ë¡œ ì˜¤ë²„ë¼ì´ë“œ
                #     temp_agent.analysis_prompt_template = st.session_state.temp_prompts['analysis']
                #     temp_agent.response_prompt_template = st.session_state.temp_prompts['response']
                    
                #     agent = temp_agent.create_workflow()
                # else:
                #     # ì„ íƒëœ ê°œë³„ í”„ë¡¬í”„íŠ¸ë“¤ì„ ì‚¬ìš©í•´ì„œ ì—ì´ì „íŠ¸ ë¹Œë“œ
                #     from src.agent.enhanced_shopping_agent import EnhancedShoppingAgent
                #     from src.config.agent_config import get_config
                    
                #     config = get_config("credit_saving")
                #     agent_instance = EnhancedShoppingAgent(config, st.session_state.active_prompt_name)
                    
                #     # ì„ íƒëœ ê°œë³„ í”„ë¡¬í”„íŠ¸ë“¤ë¡œ ì˜¤ë²„ë¼ì´ë“œ
                #     selected_analysis_data = st.session_state.prompt_manager.get_prompt_by_type(
                #         st.session_state.selected_analysis_prompt, "query_analysis"
                #     )
                #     selected_response_data = st.session_state.prompt_manager.get_prompt_by_type(
                #         st.session_state.selected_response_prompt, "model_response"
                #     )
                    
                #     if selected_analysis_data:
                #         agent_instance.analysis_prompt_template = selected_analysis_data.get('content', '')
                #     if selected_response_data:
                #         agent_instance.response_prompt_template = selected_response_data.get('content', '')
                    
                #     agent = agent_instance.create_workflow()
            
                agent = await build_agent()
                
                # ì—ì´ì „íŠ¸ê°€ ì œëŒ€ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if agent is not None:
                    st.session_state.agent = agent
                    st.success("âœ… ì—ì´ì „íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    # ë””ë²„ê·¸: ì—ì´ì „íŠ¸ íƒ€ì… í™•ì¸
                    st.info(f"ğŸ” ì—ì´ì „íŠ¸ íƒ€ì…: {type(agent).__name__}")
                    return True
                else:
                    st.error("âŒ ì—ì´ì „íŠ¸ ìƒì„± ì‹¤íŒ¨: build_agent()ê°€ Noneì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
                    return False
                    
            except Exception as e:
                st.error(f"âŒ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                st.info("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                # ë””ë²„ê·¸: ìƒì„¸ ì—ëŸ¬ ì •ë³´
                with st.expander("ğŸ› ì—ëŸ¬ ìƒì„¸ ì •ë³´"):
                    st.code(str(e))
                return False
    else:
        # ì´ë¯¸ ì´ˆê¸°í™”ëœ ê²½ìš°
        st.info("âœ… ì—ì´ì „íŠ¸ê°€ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return True


def ensure_agent_ready() -> bool:
    """
    ì—ì´ì „íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ì´ˆê¸°í™”
    
    ì´ í•¨ìˆ˜ëŠ” ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ì „ì— í˜¸ì¶œë˜ì–´ ì—ì´ì „íŠ¸ê°€ 
    ì‚¬ìš© ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    
    Returns:
        ì—ì´ì „íŠ¸ ì¤€ë¹„ ìƒíƒœ (True: ì¤€ë¹„ë¨, False: ì‹¤íŒ¨)
    """
    if st.session_state.agent is None:
        # ë™ê¸° í•¨ìˆ˜ì—ì„œ ë¹„ë™ê¸° í•¨ìˆ˜ í˜¸ì¶œ
        return asyncio.run(initialize_agent())
    return True


# =============================================================================
# ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜
# =============================================================================

async def get_response(agent, user_input: str, history: List[Tuple[str, str]]):
    """
    ì—ì´ì „íŠ¸ë¡œë¶€í„° ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°›ì•„ ì²˜ë¦¬
    
    ì´ í•¨ìˆ˜ëŠ” LangGraphì˜ astream_eventsë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³ ,
    ë„êµ¬ ì‹¤í–‰ ìƒíƒœë¥¼ ì¶”ì í•˜ë©°, ì—ëŸ¬ë¥¼ ì ì ˆíˆ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        agent: LangChain ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤
        user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
        history: ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬
        
    Yields:
        ë‹¤ì–‘í•œ íƒ€ì…ì˜ ì´ë²¤íŠ¸ ë”•ì…”ë„ˆë¦¬ (content, tool_start, tool_end, error ë“±)
    """
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
#     system_prompt = """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë³µí•©ì ì¸ ì‡¼í•‘ ìš”êµ¬ì‚¬í•­ì„ ì§€ëŠ¥ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ë‹¨ê³„ì  ê²€ìƒ‰ ì „ëµì„ í†µí•´ ì¦‰ì‹œ êµ¬ë§¤ ê°€ëŠ¥í•œ ìµœì  ìƒí’ˆì„ ì°¾ì•„ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

# # ğŸ’¡ ì£¼ìš” ê¸°ëŠ¥
# - **ì§€ëŠ¥í˜• ìš”êµ¬ì‚¬í•­ ë¶„ì„**: ì‚¬ìš©ìì˜ ìš”ì²­ì„ `í•µì‹¬ í‚¤ì›Œë“œ`, `í•„í„°ë§ ì¡°ê±´`, `ë¶€ê°€ ì¡°ê±´`ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½
# - **ë‹¨ê³„ì  ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰**: `ê¸°ë³¸ ê²€ìƒ‰` â†’ `ìœ ì‚¬ì–´ í™•ì¥` â†’ `ê²°ê³¼ í•„í„°ë§` â†’ `êµ¬ë§¤ ê°€ëŠ¥ì„± ê²€ì¦`ì˜ 4ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ ìˆ˜í–‰
# - **ì¤‘ë³µ ìƒí’ˆ ì œê±° ë° ë‹¤ì–‘ì„± í™•ë³´**: ë™ì¼/ìœ ì‚¬ ìƒí’ˆì„ ì œê±°í•˜ê³ , `ë¸Œëœë“œ`, `ê°€ê²©ëŒ€`, `ìŠ¤íƒ€ì¼`ì˜ ë‹¤ì–‘ì„±ì„ ë³´ì¥í•˜ì—¬ ìµœì¢… ì¶”ì²œ
# - **ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ì§€ëŠ¥í˜• ëŒ€ì‘**: ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•  ê²½ìš°, `í‚¤ì›Œë“œ ë³€í˜•`, `ì¹´í…Œê³ ë¦¬ í™•ì¥`, `ì¡°ê±´ ì™„í™”` ë“± ë‹¨ê³„ì ìœ¼ë¡œ ê²€ìƒ‰ ë²”ìœ„ í™•ì¥

# # ğŸ“ ì‘ë‹µ í˜•ì‹
# - **ê²€ìƒ‰ ê³¼ì • íˆ¬ëª…í™”**: ì‚¬ìš©ìì˜ ìš”ì²­ ë¶„ì„ ê²°ê³¼, ê²€ìƒ‰ ë‹¨ê³„, í•„í„°ë§, ì¤‘ë³µ ì œê±° ê³¼ì •ì„ ëª…í™•íˆ ë³´ê³ 
# - **ì¡°ê±´ë³„ ìƒí’ˆ ë¶„ë¥˜ ì¶”ì²œ**: `ì™„ë²½ ì¡°ê±´ ë§Œì¡±`, `ì£¼ìš” ì¡°ê±´ ë§Œì¡±`, `ëŒ€ì•ˆ ì¶”ì²œ` ë“± ì¡°ê±´ ì¶©ì¡± ìˆ˜ì¤€ì— ë”°ë¼ ìƒí’ˆì„ ë¶„ë¥˜í•˜ì—¬ ì œì•ˆ
# - **ë‹¤ì–‘ì„± ë³´ì¥ëœ ìµœì¢… ì¶”ì²œ**: ê° ìƒí’ˆì˜ `ë¸Œëœë“œ`, `ìƒí’ˆëª…`, `ê°€ê²©`, `ê³ ìœ  íŠ¹ì§•`ì„ ëª…ì‹œí•˜ê³ , ì¤‘ë³µì´ ì œê±°ëœ ë‹¤ì–‘í•œ ì˜µì…˜ì„ ì œê³µ

# # ğŸ”§ ê²€ìƒ‰ ìµœì í™” ê·œì¹™
# - **í”Œë«í¼ë³„ ê²€ìƒ‰ ì „ëµ**: `ë„¤ì´ë²„ì‡¼í•‘`(ê°€ê²© ë¹„êµ), `SSGëª°`(í”„ë¦¬ë¯¸ì—„), `ë¬´ì‹ ì‚¬`(íŒ¨ì…˜/íŠ¸ë Œë“œ) ë“± í”Œë«í¼ íŠ¹ì„±ì— ë§ëŠ” ê²€ìƒ‰ ìˆ˜í–‰
# - **ì‹œê°„ íš¨ìœ¨ì„± ìµœì í™”**: 5ë¶„ ë‚´ ê²°ê³¼ ë„ì¶œì„ ëª©í‘œë¡œ, ë¹ ë¥¸ íŒë‹¨ê³¼ ìš°ì„ ìˆœìœ„ ì„¤ì •ì— ê¸°ë°˜í•œ íš¨ìœ¨ì  ê²€ìƒ‰ ì§„í–‰
# """
    current_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    system_prompt = """ë‹¹ì‹ ì€ AI ê¸°ë°˜ ì „ë¬¸ ì‡¼í•‘ ì»¨ì„¤í„´íŠ¸ë¡œì„œ, ë°˜ë“œì‹œ ì‹¤ì‹œê°„ ê²€ìƒ‰ì„ í†µí•œ ê²€ì¦ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì˜ êµ¬ë§¤ ì—¬ì •ì„ ì§€ì›í•©ë‹ˆë‹¤. ë©”ëª¨ë¦¬ë‚˜ ì¶”ì¸¡ì— ì˜ì¡´í•œ ë‹µë³€ì€ ì ˆëŒ€ ê¸ˆì§€ë˜ë©°, ëª¨ë“  ì¶”ì²œì€ ë„êµ¬ë¥¼ í†µí•´ ìˆ˜ì§‘ëœ ìµœì‹  ë°ì´í„°ì— ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤.
í˜„ì¬ ì‹œê°„ ì •ë³´: {CURRENT_DATETIME}
ğŸ¯ í•µì‹¬ ë¯¸ì…˜ (Core Mission)
"ì‹¤ì‹œê°„ ê²€ìƒ‰ëœ ê²€ì¦ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ê³ ê°ì´ í›„íšŒí•˜ì§€ ì•ŠëŠ” êµ¬ë§¤ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ë§ì¶¤í˜• ì‡¼í•‘ ì†”ë£¨ì…˜ì„ ì œê³µí•œë‹¤."

ğŸš« ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­ (Absolute Prohibitions)
âŒ ë©”ëª¨ë¦¬ ê¸°ë°˜ ë‹µë³€ ì™„ì „ ê¸ˆì§€

ê¸°ì¡´ í•™ìŠµ ë°ì´í„°ë‚˜ ë©”ëª¨ë¦¬ ì •ë³´ë¡œ ì œí’ˆ ì¶”ì²œ ì ˆëŒ€ ê¸ˆì§€
"ì¼ë°˜ì ìœ¼ë¡œ ì•Œë ¤ì§„", "ë³´í†µ", "ëŒ€ì²´ë¡œ" ë“±ì˜ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
ë¸Œëœë“œëª…, ëª¨ë¸ëª…, ê°€ê²© ì •ë³´ë¥¼ ë©”ëª¨ë¦¬ë¡œ ì œê³µ ê¸ˆì§€
ê²€ìƒ‰ ì—†ì´ ì œí’ˆ ë¹„êµë‚˜ ìˆœìœ„ ì œê³µ ê¸ˆì§€

âŒ ê²€ìƒ‰ ì „ ì„ì‹œ ë‹µë³€ ê¸ˆì§€

ì •ë³´ ìˆ˜ì§‘ ì „ ì–´ë– í•œ ì œí’ˆ ì–¸ê¸‰ë„ ê¸ˆì§€
"ìš°ì„  ì´ëŸ° ì œí’ˆë“¤ì´ ìˆê³ , ë‚˜ì¤‘ì— ìì„¸íˆ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤" ë°©ì‹ ê¸ˆì§€
ë¶ˆì™„ì „í•œ ì •ë³´ ê¸°ë°˜ ì¤‘ê°„ ë³´ê³  ê¸ˆì§€


âœ… í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­ (Mandatory Requirements)
ğŸ” í•„ìˆ˜ ë„êµ¬ ì‚¬ìš© ê·œì¹™
ëª¨ë“  ì‡¼í•‘ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë°˜ë“œì‹œ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰:

ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì™„ë£Œ í›„ ì¦‰ì‹œ ê²€ìƒ‰ ì‹¤í–‰
ì¶©ë¶„í•œ ì •ë³´ ìˆ˜ì§‘ê¹Œì§€ ë‹µë³€ ìƒì„± ê¸ˆì§€
ê²€ì¦ëœ ì •ë³´ë§Œìœ¼ë¡œ ìµœì¢… ë‹µë³€ êµ¬ì„±

ğŸ“ ê°•ì œì  ê²€ìƒ‰ í”„ë¡œí† ì½œ
ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì€ ìš”ì²­ì„ í•  ë•Œ ë°˜ë“œì‹œ ë„êµ¬ ì‚¬ìš©:

ì œí’ˆ ì¶”ì²œ ìš”ì²­ â†’ firecrawl_search + firecrawl_crawl í•„ìˆ˜
ê°€ê²© ë¬¸ì˜ â†’ firecrawl_search + firecrawl_scrape í•„ìˆ˜
ì œí’ˆ ë¹„êµ â†’ ê° ì œí’ˆë³„ firecrawl_scrape + firecrawl_extract í•„ìˆ˜
ë¦¬ë·° ì •ë³´ â†’ firecrawl_crawl + web_search í•„ìˆ˜
í• ì¸/í”„ë¡œëª¨ì…˜ ì •ë³´ â†’ firecrawl_search + web_search í•„ìˆ˜
ë¸Œëœë“œ/ëª¨ë¸ ë¬¸ì˜ â†’ firecrawl_scrape + firecrawl_extract í•„ìˆ˜

âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ëŒ€ì‘

ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶ˆì¶©ë¶„í•œ ê²½ìš°: "ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•©ë‹ˆë‹¤" ëª…ì‹œ í›„ ì¬ê²€ìƒ‰
ê²€ìƒ‰ ë„êµ¬ ì˜¤ë¥˜ ì‹œ: "í˜„ì¬ ì •í™•í•œ ì •ë³´ ìˆ˜ì§‘ì´ ì–´ë ¤ìš´ ìƒí™©ì…ë‹ˆë‹¤" ì•ˆë‚´
ì ˆëŒ€ ë©”ëª¨ë¦¬ ì •ë³´ë¡œ ëŒ€ì²´í•˜ì§€ ì•ŠìŒ


ğŸ”§ ê°œì„ ëœ ìš´ì˜ í”„ë¡œì„¸ìŠ¤ (Enhanced Operating Process)
Phase 1: ìš”êµ¬ì‚¬í•­ ë¶„ì„ (Requirements Analysis)
ëª©í‘œ: ê²€ìƒ‰ì— í•„ìš”í•œ ëª¨ë“  ì •ë³´ ìˆ˜ì§‘
1. ì‚¬ìš©ì ì§ˆë¬¸ ë¶„í•´
   - ì œí’ˆ ì¹´í…Œê³ ë¦¬ ì‹ë³„
   - ì˜ˆì‚° ë²”ìœ„ í™•ì¸
   - ì£¼ìš” ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­ íŒŒì•…
   - ì‚¬ìš© ëª©ì /í™˜ê²½ í™•ì¸

2. ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½
   - í•„ìš”í•œ ê²€ìƒ‰ ë„êµ¬ ê²°ì •
   - ê²€ìƒ‰ í‚¤ì›Œë“œ ë° ë²”ìœ„ ì„¤ì •
   - ì •ë³´ ê²€ì¦ ë°©ë²• ê³„íš

3. ê²€ìƒ‰ ì‹¤í–‰ ì„ ì–¸
   "ì •í™•í•œ ì •ë³´ë¥¼ ìœ„í•´ ì‹¤ì‹œê°„ ê²€ìƒ‰ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤."
Phase 2: ê°•ì œì  ì •ë³´ ìˆ˜ì§‘ (Mandatory Information Collection)
ì ˆëŒ€ ê·œì¹™: ì´ ë‹¨ê³„ì—ì„œëŠ” ì–´ë– í•œ ì¶”ì²œì´ë‚˜ ì œí’ˆ ì–¸ê¸‰ë„ ê¸ˆì§€
ğŸ” í•„ìˆ˜ ê²€ìƒ‰ ìˆœì„œ:
1. firecrawl_search: ê´‘ë²”ìœ„í•œ ì œí’ˆ ë° ê°€ê²© ê²€ìƒ‰
2. firecrawl_crawl: ì œí’ˆ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘
3. firecrawl_scrape: êµ¬ì²´ì ì¸ ì œí’ˆ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
4. firecrawl_extract: íŠ¹ì • ì •ë³´ ì¶”ì¶œ
5. web_search: ìµœì‹  ë¦¬ë·°, íŠ¸ë Œë“œ, ë‰´ìŠ¤ ì •ë³´ (ë³´ì™„ì  ì‚¬ìš©)

âš ï¸ ê²€ìƒ‰ ì¤‘ ì ˆëŒ€ ê¸ˆì§€:
- "ì¼ë°˜ì ìœ¼ë¡œ ì´ëŸ° ì œí’ˆë“¤ì´ ì¢‹ìŠµë‹ˆë‹¤" 
- "ì œê°€ ì•Œê¸°ë¡œëŠ”..."
- "ë³´í†µ ì¶”ì²œë˜ëŠ” ì œí’ˆì€..."
Phase 3: ì •ë³´ ê²€ì¦ ë° ë¶„ì„ (Verification & Analysis)
ëª©í‘œ: ìˆ˜ì§‘ëœ ì •ë³´ì˜ ì‹ ë¢°ì„± ê²€ì¦ ë° ì¢…í•© ë¶„ì„
ğŸ“Š ê²€ì¦ í”„ë¡œì„¸ìŠ¤:
1. ë‹¤ì¤‘ ì†ŒìŠ¤ êµì°¨ ê²€ì¦
   - ìµœì†Œ 3ê°œ ì´ìƒ ë…ë¦½ ì†ŒìŠ¤ í™•ì¸
   - ê°€ê²© ì •ë³´ ì¼ì¹˜ì„± ê²€í† 
   - ì œí’ˆ ì‚¬ì–‘ ì •í™•ì„± í™•ì¸

2. ì •ë³´ í’ˆì§ˆ í‰ê°€
   - ìµœì‹ ì„± í™•ì¸ (ë°œí–‰ì¼, ì—…ë°ì´íŠ¸ì¼)
   - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ì¸ì§€ íŒë‹¨
   - í¸í–¥ì„± ë˜ëŠ” ê´‘ê³ ì„± ë‚´ìš© ì‹ë³„

3. ì¢…í•© ë¶„ì„ ì‹¤ì‹œ
   - ê°€ì„±ë¹„ ë¶„ì„
   - ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ì í•©ì„± í‰ê°€
   - ì¥ë‹¨ì  ê°ê´€ì  ë¹„êµ
Phase 4: ê²€ì¦ëœ ì†”ë£¨ì…˜ ì œì‹œ (Verified Solution Delivery)
ê·œì¹™: ê²€ì¦ ì™„ë£Œëœ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ êµ¬ì„±

ğŸ“‹ í•„ìˆ˜ ë‹µë³€ í…œí”Œë¦¿
markdownğŸ” **ì •ë³´ ìˆ˜ì§‘ í˜„í™©**
- ì‹¤ì‹œê°„ ê²€ìƒ‰ ì™„ë£Œ: [ìˆ˜í–‰ ì‹œê°„]
- ê²€ì¦ëœ ì†ŒìŠ¤: [ì£¼ìš” ì†ŒìŠ¤ ìˆ˜ëŸ‰]

ğŸ¯ **ê²€ì¦ëœ ì¶”ì²œ ê²°ê³¼**
[ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ì¶”ì²œ ë‚´ìš©]

ğŸ“Š **ìƒì„¸ ë¹„êµ ë¶„ì„**
[ì‹¤ì œ ê²€ìƒ‰ëœ ì œí’ˆë“¤ì˜ ë¹„êµ ì •ë³´]

ğŸ’° **ì‹¤ì œ ê°€ê²© ì •ë³´**
[ê²€ìƒ‰ìœ¼ë¡œ í™•ì¸ëœ ìµœì‹  ê°€ê²©]

â­ **ì‹¤ì œ ì‚¬ìš©ì ë¦¬ë·° ì¢…í•©**
[ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë¦¬ë·° ì •ë³´]

ğŸ›’ **êµ¬ë§¤ ê°€ì´ë“œ**
[ê²€ìƒ‰ ê¸°ë°˜ êµ¬ë§¤ ì¡°ì–¸]

---
ğŸ“‹ **ì°¸ê³ í•œ ì •ë³´ ì¶œì²˜**
ğŸ”— **ì£¼ìš” ì°¸ê³  ì‚¬ì´íŠ¸**
- [ì‹¤ì œ ê²€ìƒ‰í•œ ì‚¬ì´íŠ¸ë“¤]

ğŸ’¡ **ì •ë³´ ì£¼ì˜ì‚¬í•­**
- ëª¨ë“  ì •ë³´ëŠ” [ê²€ìƒ‰ ìˆ˜í–‰ ì‹œê°„] ê¸°ì¤€ì…ë‹ˆë‹¤
- ê°€ê²© ë° ì¬ê³ ëŠ” ì‹¤ì‹œê°„ ë³€ë™ ê°€ëŠ¥í•©ë‹ˆë‹¤
- ìµœì¢… êµ¬ë§¤ ì „ í•´ë‹¹ ì‡¼í•‘ëª°ì—ì„œ ì¬í™•ì¸ ê¶Œì¥í•©ë‹ˆë‹¤

ğŸ›¡ï¸ ë‚´ë¶€ ê²€ìƒ‰ ê°•ì œ ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸
(ì‚¬ìš©ìì—ê²Œ ë…¸ì¶œí•˜ì§€ ì•Šê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ í™•ì¸)
âœ… ë‹µë³€ ì „ í•„ìˆ˜ ë‚´ë¶€ í™•ì¸ì‚¬í•­:

 firecrawl_search/ì£¼ìš” ì‡¼í•‘ì±„ë„ êµì°¨ ê²€ìƒ‰ ì™„ë£Œ
 ê°€ê²©/ìƒí’ˆëª…/ë¸Œëœë“œ/ìƒì„¸ ëª¨ë‘ ìµœì‹  ì‹¤ì‹œê°„ ì •ë³´ ë°˜ì˜
 ëŒ€í‘œ ì¸ê¸°ìƒí’ˆ/í›„ê¸°/ì‹¤ì‚¬ìš© íŒ ì¢…í•©
 ë©”ëª¨ë¦¬ ê¸°ë°˜ ë‹µë³€ ì¼ì²´ ì—†ìŒ
 ê´€ë ¨ ì œí’ˆì— ëŒ€í•´ firecrawl_search ì‹¤í–‰í–ˆëŠ”ê°€?
 ì œí’ˆ ê´€ë ¨ ì •ë³´ë¥¼ firecrawl_crawlë¡œ ìˆ˜ì§‘í–ˆëŠ”ê°€?
 êµ¬ì²´ì ì¸ ì œí’ˆ ì •ë³´ë¥¼ firecrawl_scrapeë¡œ í™•ì¸í–ˆëŠ”ê°€?
 í•„ìš”í•œ íŠ¹ì • ì •ë³´ë¥¼ firecrawl_extractë¡œ ì¶”ì¶œí–ˆëŠ”ê°€?
 ê°€ê²© ì •ë³´ê°€ ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼ì¸ê°€?
 ëª¨ë“  ì œí’ˆëª…/ëª¨ë¸ëª…ì´ ê²€ìƒ‰ìœ¼ë¡œ í™•ì¸ëœ ê²ƒì¸ê°€?
 ì¶”ì¸¡ì„± ë‚´ìš©ì´ ì™„ì „íˆ ì œê±°ë˜ì—ˆëŠ”ê°€?

âŒ ë‹µë³€ ê±°ë¶€ ì¡°ê±´:

ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë‹µë³€ ì‹œë„
"ì¼ë°˜ì ìœ¼ë¡œ", "ë³´í†µ" ë“±ì˜ í‘œí˜„ ì‚¬ìš©
ë©”ëª¨ë¦¬ ì •ë³´ ê¸°ë°˜ ì œí’ˆ ì¶”ì²œ
ê²€ìƒ‰ ê²°ê³¼ ì—†ì´ ê°€ê²©/ì‚¬ì–‘ ì •ë³´ ì œê³µ

ì¤‘ìš”: ìœ„ ì²´í¬ë¦¬ìŠ¤íŠ¸ëŠ” ì‚¬ìš©ì ë‹µë³€ì— í¬í•¨í•˜ì§€ ì•Šê³ , ì‹œìŠ¤í…œ ë‚´ë¶€ì—ì„œë§Œ í™•ì¸í•˜ì—¬ í’ˆì§ˆì„ ë³´ì¥í•˜ëŠ” ìš©ë„ë¡œ ì‚¬ìš©

âš ï¸ ì˜ˆì™¸ ì²˜ë¦¬ ë° ì˜¤ë¥˜ ë°©ì§€
ğŸ” ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ëŒ€ì‘
"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ë¡œ ì •í™•í•œ ì •ë³´ ìˆ˜ì§‘ì´ ì–´ë ¤ìš´ ìƒí™©ì…ë‹ˆë‹¤:
- [êµ¬ì²´ì ì¸ ê²€ìƒ‰ ì‹¤íŒ¨ ì´ìœ ]
- [ëŒ€ì•ˆì  ì •ë³´ ìˆ˜ì§‘ ë°©ë²•]
- [ì‚¬ìš©ìê°€ ì§ì ‘ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë°©ë²•]

ë©”ëª¨ë¦¬ë‚˜ ì¶”ì¸¡ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ëŠ” ê²ƒë³´ë‹¤ëŠ”, ì •í™•í•œ ì •ë³´ë¥¼ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤:
[êµ¬ì²´ì ì¸ ëŒ€ì•ˆ ë°©ì•ˆ]"
ğŸš« ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ í‘œí˜„

"ì¼ë°˜ì ìœ¼ë¡œ ì¶”ì²œë˜ëŠ”..."
"ì œê°€ ì•Œê¸°ë¡œëŠ”..."
"ë³´í†µ ì´ëŸ° ì œí’ˆë“¤ì´..."
"ëŒ€ì²´ë¡œ ì¢‹ì€ í‰ê°€ë¥¼..."
"ì•„ë§ˆë„..." / "ì¶”ì •í•˜ê±´ëŒ€..."

âœ… ê¶Œì¥ í‘œí˜„

"ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼ì— ë”°ë¥´ë©´..."
"ë°©ê¸ˆ í™•ì¸í•œ ì •ë³´ë¡œëŠ”..."
"í˜„ì¬ ì‹œì  ê²€ìƒ‰ ê²°ê³¼..."
"ìµœì‹  ê²€ìƒ‰ ì •ë³´ ê¸°ì¤€ìœ¼ë¡œ..."


ğŸ¯ ì„±ëŠ¥ ì§€í‘œ ë° í’ˆì§ˆ ê´€ë¦¬
ğŸ“Š í•„ìˆ˜ ë‹¬ì„± ì§€í‘œ

ë„êµ¬ ì‚¬ìš©ë¥ : 100% (ì‡¼í•‘ ê´€ë ¨ ì§ˆë¬¸ ì‹œ)
ë©”ëª¨ë¦¬ ê¸°ë°˜ ë‹µë³€: 0%
ê²€ìƒ‰ ì „ ì¶”ì²œ ì œê³µ: 0ê±´
ì •ë³´ ì¶œì²˜ ëª…ì‹œìœ¨: 100%

ğŸ”„ ì§€ì†ì  ê°œì„ 

ê²€ìƒ‰ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„
ì •ë³´ ìˆ˜ì§‘ íš¨ìœ¨ì„± ê°œì„ 
ì‚¬ìš©ì ë§Œì¡±ë„ ê¸°ë°˜ í”„ë¡œì„¸ìŠ¤ ìµœì í™”


ğŸ”¥ í•µì‹¬ ì›ì¹™ ì¬ê°•ì¡°:

ê²€ìƒ‰ ì—†ëŠ” ë‹µë³€ì€ ì ˆëŒ€ ê¸ˆì§€
ëª¨ë“  ì œí’ˆ ì •ë³´ëŠ” ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš©
ë©”ëª¨ë¦¬ ê¸°ë°˜ ì¶”ì²œì€ 100% ì°¨ë‹¨
ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ì „ê¹Œì§€ ì¶”ì²œ ì§€ì—°
ê²€ì¦ëœ ì •ë³´ë§Œìœ¼ë¡œ ìµœì¢… ë‹µë³€ êµ¬ì„±
"""

    
    # ë„êµ¬ ì‹¤í–‰ ì¶”ì ê¸° ì´ˆê¸°í™”
    tracker = ToolExecutionTracker()
    try:
        print(f"system_prompt : {system_prompt.format(CURRENT_DATETIME=current_datetime)}")
    except Exception as e:
        print(f"system_prompt error: {e}")
    
    # Enhanced Agent ìƒíƒœ êµ¬ì„±
    initial_state = {
        "user_query": user_input,
        # "messages": [("system", system_prompt)] + history + [("user", user_input)],
        "messages": [("system", system_prompt.format(CURRENT_DATETIME=current_datetime))] + history + [("user", user_input)],
        "processing_status": "ì‹œì‘"
    }

    try:
        # LangGraph ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
        # print(f"initial_state: {initial_state}")
        async for event in agent.astream_events(initial_state, version="v1"):
            event_type = event["event"]
            # print(f"event: {event}")
            
            if event_type == "on_chat_model_stream":
                # LLM ì‘ë‹µ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°
                content = event["data"]["chunk"].content
                if content:
                    yield {"type": "content", "data": content}
                    
            elif event_type == "on_tool_start":
                # ë„êµ¬ ì‹¤í–‰ ì‹œì‘
                run_id = str(event['run_id'])
                tool_name = event['name']
                tool_input = event['data'].get('input')
                
                call_data = tracker.start_tool_execution(run_id, tool_name, tool_input, event)
                
                yield {
                    "type": "tool_start",
                    "run_id": run_id,
                    "name": tool_name,
                    "input": tool_input,
                    "call_data": call_data
                }
                
            elif event_type == "on_tool_end":
                print(f"event tool end: {event}")
                # ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ
                run_id = str(event['run_id'])
                tool_output = event['data'].get('output')
                
                updated_call_data = tracker.finish_tool_execution(run_id, tool_output)
                
                if updated_call_data:
                    yield {
                        "type": "tool_end",
                        "run_id": run_id,
                        "name": updated_call_data['name'],
                        "output": updated_call_data['output'],
                        "call_data": updated_call_data
                    }
                    
            elif event_type == "on_chain_stream" and event["metadata"].get("langgraph_node") == "tools":
                print(f"event on_chain_stream tools: {event}")

                
                chunk = event.get("data", {}).get("chunk", {})
                messages = chunk.get("messages", [])

                for msg in messages:
                    if isinstance(msg, ToolMessage) and hasattr(msg, 'status') and msg.status == 'error':
                        updated_cells = tracker.handle_group_error(event)

                        for call_data in updated_cells:
                            yield { 
                                "type": "tool_error",
                                "run_id": call_data["run_id"],
                                "tool_name": call_data["name"],
                                "error_message": call_data["error"],
                                "call_data": call_data,
                                "tools_namespace": call_data.get("tools_namespace")                                
                            }
                
                
            elif event_type == "on_chat_model_start":
                print(f"on_chat_model_start: {event}")
        
                                
    except Exception as e:
        # ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ ì²˜ë¦¬
        error_message = f"ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        yield {
            "type": "stream_error",
            "error": error_message,
            "traceback": traceback.format_exc()
        }


# =============================================================================
# UI ë Œë”ë§ í•¨ìˆ˜
# =============================================================================

def render_tool_call(call_data: Dict[str, Any]) -> None:
    """
    ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ Streamlit UIë¡œ ë Œë”ë§
    
    ë„êµ¬ì˜ ì´ë¦„, ì…ë ¥, ì¶œë ¥, ì‹¤í–‰ ì‹œê°„, ì—ëŸ¬ ì •ë³´ ë“±ì„ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ
    í‘œì‹œí•©ë‹ˆë‹¤. ì—ëŸ¬ê°€ ìˆëŠ” ê²½ìš° ì‹œê°ì ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.
    
    Args:
        call_data: ë Œë”ë§í•  ë„êµ¬ í˜¸ì¶œ ë°ì´í„°
    """
    tool_name = call_data['name']
    tool_input = call_data.get('input', {})
    output = call_data.get('output')
    error = call_data.get('error')
    tools_namespace = call_data.get('tools_namespace', 'Unknown')
    is_error = error is not None or (isinstance(output, str) and 'ToolException' in output)

    # ì‹¤í–‰ ì‹œê°„ ê³„ì‚° ë° í‘œì‹œ
    execution_time = ""
    if call_data.get('start_time') and call_data.get('end_time'):
        duration = call_data['end_time'] - call_data['start_time']
        execution_time = f" ({duration:.2f}ì´ˆ)"

    # ë„êµ¬ ì…ë ¥ì— ë”°ë¥¸ ìš”ì•½ ì •ë³´ ìƒì„±
    summary = _generate_tool_summary(tool_name, tool_input)

    # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
    st.markdown(f'**ë„êµ¬:** `{tool_name}`{summary}{execution_time}')
    st.markdown(f'**ê·¸ë£¹:** `{tools_namespace}`')

    # ì—ëŸ¬ ìƒíƒœì¸ ê²½ìš° ê²½ê³  ë©”ì‹œì§€ í‘œì‹œ
    if is_error:
        st.error(f"âš ï¸ ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {error or output}")

    # ìƒì„¸ ì •ë³´ë¥¼ í™•ì¥ ê°€ëŠ¥í•œ ì„¹ì…˜ìœ¼ë¡œ í‘œì‹œ
    with st.expander("ìƒì„¸ ì •ë³´ ë³´ê¸°"):
        st.markdown("##### ì…ë ¥ ë°ì´í„°")
        st.code(json.dumps(tool_input, indent=2, ensure_ascii=False), language='json')
        
        if call_data.get("finished"):
            st.markdown("##### ì‹¤í–‰ ê²°ê³¼")
            _render_tool_output(output, error, is_error)


def _generate_tool_summary(tool_name: str, tool_input: Dict[str, Any]) -> str:
    """
    ë„êµ¬ ì…ë ¥ì— ê¸°ë°˜í•œ ìš”ì•½ ì •ë³´ ìƒì„±
    
    Args:
        tool_name: ë„êµ¬ ì´ë¦„
        tool_input: ë„êµ¬ ì…ë ¥ ë°ì´í„°
        
    Returns:
        ìƒì„±ëœ ìš”ì•½ ë¬¸ìì—´
    """
    if not isinstance(tool_input, dict):
        return ''
    
    if tool_name == 'firecrawl.scrape' and 'url' in tool_input:
        return f" - `{tool_input['url']}`"
    elif tool_name == 'firecrawl.search' and 'query' in tool_input:
        return f" - `{tool_input['query']}`"
    
    return ''


def _render_tool_output(output: Any, error: str, is_error: bool) -> None:
    """
    ë„êµ¬ ì¶œë ¥ ê²°ê³¼ ë Œë”ë§
    
    Args:
        output: ë„êµ¬ ì¶œë ¥
        error: ì—ëŸ¬ ë©”ì‹œì§€
        is_error: ì—ëŸ¬ ìƒíƒœ ì—¬ë¶€
    """
    print(f"output: {output}")
    if is_error:
        st.markdown("**ì—ëŸ¬ ìƒì„¸:**")
        error_text = error or output
        st.code(error_text, language='text')
    elif output is None:
        st.markdown("_(ì¶œë ¥ ì—†ìŒ)_")
    elif isinstance(output, ToolMessage):
        st.code(output.content)
    elif isinstance(output, str):
        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì¼ë¶€ë§Œ í‘œì‹œ
        display_output = output
        if len(output) > 1000:
            display_output = output[:1000] + "\n... (ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œí•©ë‹ˆë‹¤)"
        st.code(display_output, language='text')
    elif isinstance(output, (dict, list)):
        st.code(json.dumps(output, indent=2, ensure_ascii=False), language='json')
    else:
        st.code(str(output), language='text')


def determine_tool_status(call_data: Dict[str, Any]) -> Tuple[str, str]:
    """
    ë„êµ¬ ìƒíƒœì— ë”°ë¥¸ UI ìƒíƒœ ë° í…ìŠ¤íŠ¸ ê²°ì •
    
    Args:
        call_data: ë„êµ¬ í˜¸ì¶œ ë°ì´í„°
        
    Returns:
        (ìƒíƒœ í…ìŠ¤íŠ¸, UI ìƒíƒœ) íŠœí”Œ
    """
    is_error = (call_data.get('error') is not None or 
               (isinstance(call_data.get('output'), str) and 
                'ToolException' in call_data.get('output', '')))
    
    if not call_data.get('finished'):
        return "ì‹¤í–‰ ì¤‘", "running"
    elif is_error:
        return "ì‹¤íŒ¨", "error"
    else:
        return "ì™„ë£Œ", "complete"


# =============================================================================
# UI ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ í•¨ìˆ˜
# =============================================================================

async def stream_and_update_ui(response_stream, message_container):
    """
    ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ì„ ì²˜ë¦¬í•˜ê³  ì‹¤ì‹œê°„ìœ¼ë¡œ UIë¥¼ ì—…ë°ì´íŠ¸
    
    ì´ í•¨ìˆ˜ëŠ” ì—ì´ì „íŠ¸ì˜ ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ì„ ë°›ì•„ì„œ í…ìŠ¤íŠ¸ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œí•˜ê³ ,
    ë„êµ¬ ì‹¤í–‰ ìƒíƒœëŠ” ë³„ë„ì˜ ìƒíƒœ ì»´í¬ë„ŒíŠ¸ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
    
    Args:
        response_stream: ì—ì´ì „íŠ¸ ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ ì´í„°ë ˆì´í„°
        message_container: Streamlit ì»¨í…Œì´ë„ˆ ê°ì²´
        
    Returns:
        ë©”ì‹œì§€ êµ¬ì„± ìš”ì†Œ ë¦¬ìŠ¤íŠ¸ (í…ìŠ¤íŠ¸ ë° ë„êµ¬ í˜¸ì¶œ ì •ë³´)
    """
    # UI ìƒíƒœ ê´€ë¦¬ ë³€ìˆ˜ë“¤
    message_parts = []  # ìµœì¢…ì ìœ¼ë¡œ ì €ì¥ë  ë©”ì‹œì§€ êµ¬ì„± ìš”ì†Œë“¤
    active_tool_ui = {}  # í˜„ì¬ í™œì„±í™”ëœ ë„êµ¬ UI ì»´í¬ë„ŒíŠ¸ë“¤ {run_id: (placeholder, status_ui, call_data)}
    
    # í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë”
    current_text_placeholder = message_container.empty()
    current_text_content = ""

    async for event in response_stream:
        event_type = event["type"]
        
        if event_type == "content":
            # LLM í…ìŠ¤íŠ¸ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
            current_text_content += event["data"]
            # ì»¤ì„œ í‘œì‹œë¥¼ ìœ„í•´ 'â–Œ' ë¬¸ì ì¶”ê°€
            current_text_placeholder.markdown(current_text_content + "â–Œ")

        elif event_type == "tool_start":
            # ë„êµ¬ ì‹¤í–‰ ì‹œì‘ ì‹œ UI ì²˜ë¦¬
            # 1. í˜„ì¬ê¹Œì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ í™•ì •í•˜ì—¬ í‘œì‹œ
            if current_text_content:
                current_text_placeholder.markdown(current_text_content)
                message_parts.append({"type": "text", "data": current_text_content})
                current_text_content = ""

            # 2. ë„êµ¬ í˜¸ì¶œ ë°ì´í„°ë¥¼ ë©”ì‹œì§€ íŒŒíŠ¸ì— ì¶”ê°€
            call_data = event["call_data"]
            message_parts.append({"type": "tool_call", "data": call_data})
            
            # 3. ë„êµ¬ ì‹¤í–‰ ìƒíƒœë¥¼ ìœ„í•œ UI ì»´í¬ë„ŒíŠ¸ ìƒì„±
            status_placeholder = message_container.empty()
            with status_placeholder:
                status_ui = st.status(f"ë„êµ¬ ì‹¤í–‰ ì¤‘: {event['name']}", expanded=True)
                with status_ui:
                    render_tool_call(call_data)
            
            # í™œì„± ë„êµ¬ UI ëª©ë¡ì— ì¶”ê°€
            active_tool_ui[event["run_id"]] = (status_placeholder, status_ui, call_data)

            # 4. ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ í”Œë ˆì´ìŠ¤í™€ë” ìƒì„±
            current_text_placeholder = message_container.empty()
        
        elif event_type == "tool_end":
            # ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ ì‹œ UI ì—…ë°ì´íŠ¸
            run_id = event["run_id"]
            updated_call_data = event["call_data"]
            if run_id in active_tool_ui:
                status_placeholder, status_ui, old_call_data = active_tool_ui[run_id]
                
                # ê¸°ì¡´ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸
                old_call_data.update(updated_call_data)
                # ë„êµ¬ ìƒíƒœ ê²°ì •
                status_text, status_state = determine_tool_status(updated_call_data)

                # UI ì—…ë°ì´íŠ¸ (í™•ì¥í•˜ì§€ ì•Šì€ ìƒíƒœë¡œ ë³€ê²½)
                status_placeholder.empty()
                with status_placeholder:
                    with st.status(f"ë„êµ¬ {status_text}: {updated_call_data['name']}", 
                                 expanded=False, state=status_state):
                        render_tool_call(updated_call_data)
                
                # ì™„ë£Œëœ ë„êµ¬ëŠ” í™œì„± ëª©ë¡ì—ì„œ ì œê±°
                active_tool_ui.pop(run_id)

        elif event_type == "tool_error":
            # ë„êµ¬ ì—ëŸ¬ ë° íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
            run_id = event["run_id"]
            updated_call_data = event["call_data"]

            if run_id in active_tool_ui:
                status_placeholder, status_ui, old_call_data = active_tool_ui[run_id]
                
                # ë°ì´í„° ì—…ë°ì´íŠ¸
                old_call_data.update(updated_call_data)

                # UI ì—…ë°ì´íŠ¸
                status_placeholder.empty()
                with status_placeholder:
                    with st.status(f"ë„êµ¬ ì˜¤ë¥˜ : {updated_call_data['name']}", 
                                 expanded=False, state="error"):
                        render_tool_call(updated_call_data)
                
                active_tool_ui.pop(run_id)
        
        elif event_type == "stream_error":
            # ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì—ëŸ¬ í‘œì‹œ
            st.error(f"âš ï¸ ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {event['error']}")
            if event.get('traceback'):
                with st.expander("ì˜¤ë¥˜ ìƒì„¸ ì •ë³´"):
                    st.code(event['traceback'], language='text')

        # UI ë°˜ì‘ì„±ì„ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
        await asyncio.sleep(0.01)

    # ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ í›„ ì •ë¦¬ ì‘ì—…
    # 1. ë‚¨ì€ í…ìŠ¤íŠ¸ í™•ì •
    if current_text_content:
        current_text_placeholder.markdown(current_text_content)
        message_parts.append({"type": "text", "data": current_text_content})
    
    # 2. ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì€ ë„êµ¬ë“¤ ê°•ì œ ì™„ë£Œ ì²˜ë¦¬
    for run_id, (status_placeholder, status_ui, call_data) in active_tool_ui.items():
        if not call_data.get("finished"):
            # ë¯¸ì™„ë£Œ ë„êµ¬ë¥¼ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
            call_data["output"] = "ToolException: ë„êµ¬ ì‹¤í–‰ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            call_data["error"] = "ë„êµ¬ ì‹¤í–‰ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            call_data["finished"] = True
            call_data["end_time"] = asyncio.get_event_loop().time()
            
            # UI ì—…ë°ì´íŠ¸
            status_placeholder.empty()
            with status_placeholder:
                with st.status(f"ë„êµ¬ ë¯¸ì™„ë£Œ: {call_data['name']}", 
                             expanded=False, state="error"):
                    render_tool_call(call_data)
    
    return message_parts


def generate_history_summary(message_parts: List[Dict[str, Any]]) -> str:
    """
    ë©”ì‹œì§€ íŒŒíŠ¸ë“¤ë¡œë¶€í„° ëŒ€í™” íˆìŠ¤í† ë¦¬ìš© ìš”ì•½ ìƒì„±
    
    í…ìŠ¤íŠ¸ ì‘ë‹µê³¼ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì €ì¥í• 
    ìš”ì•½ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        message_parts: ë©”ì‹œì§€ êµ¬ì„± ìš”ì†Œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ìƒì„±ëœ ìš”ì•½ ë©”ì‹œì§€
    """
    # í…ìŠ¤íŠ¸ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ì—¬ ì—°ê²°
    text_response = "".join([
        part["data"] for part in message_parts if part["type"] == "text"
    ])
    
    # í…ìŠ¤íŠ¸ ì‘ë‹µì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if text_response.strip():
        return text_response
    
    # í…ìŠ¤íŠ¸ ì‘ë‹µì´ ì—†ê³  ë„êµ¬ë§Œ ì‚¬ìš©ëœ ê²½ìš° ìš”ì•½ ìƒì„±
    tool_calls = [part for part in message_parts if part["type"] == "tool_call"]
    if not tool_calls:
        return "ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    
    tool_count = len(tool_calls)
    failed_tools = sum(1 for part in tool_calls 
                     if (part["data"].get("error") is not None or 
                         (isinstance(part["data"].get("output"), str) and 
                          'ToolException' in part["data"].get("output", ""))))
    
    # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ì— ë”°ë¥¸ ìš”ì•½ ë©”ì‹œì§€ ìƒì„±
    if failed_tools == tool_count:
        return f"ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ {tool_count}ê°œì˜ ë„êµ¬ë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ ëª¨ë‘ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    elif failed_tools > 0:
        return f"{tool_count}ê°œì˜ ë„êµ¬ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ({failed_tools}ê°œ ì‹¤íŒ¨)"
    else:
        return f"{tool_count}ê°œì˜ ë„êµ¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."


# =============================================================================
# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
# =============================================================================

# =============================================================================
# í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ UI ì»´í¬ë„ŒíŠ¸
# =============================================================================

def extract_prompt_summary(prompt_text: str) -> str:
    """í”„ë¡¬í”„íŠ¸ì—ì„œ ì˜ë¯¸ìˆëŠ” ìš”ì•½ ì •ë³´ ì¶”ì¶œ"""
    if not prompt_text:
        return "ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"
    
    # ì£¼ìš” í‚¤ì›Œë“œë“¤ì„ ì°¾ì•„ì„œ í”„ë¡¬í”„íŠ¸ì˜ ëª©ì  íŒŒì•…
    keywords_analysis = {
        "ì§ˆë¬¸ ë¶„ì„": ["ì§ˆë¬¸ì„ ë¶„ì„", "ì •ë³´ë¥¼ ì¶”ì¶œ", "JSON í˜•ì‹", "ê²€ìƒ‰ í‚¤ì›Œë“œ"],
        "ìƒí’ˆ ì¶”ì²œ": ["ì‡¼í•‘ ì»¨ì„¤í„´íŠ¸", "ìƒí’ˆ ì¶”ì²œ", "êµ¬ë§¤ ê°€ì´ë“œ", "ì „ë¬¸ì "],
        "êµ¬ì¡°í™” ì¶œë ¥": ["JSON", "êµ¬ì¡°í™”", "í…œí”Œë¦¿", "í˜•ì‹"],
        "ê°œì¸í™”": ["ê°œì¸í™”", "ë§ì¶¤", "ì‚¬ìš©ì", "ìƒí™©"],
        "ì „ë¬¸ì„±": ["ì „ë¬¸", "ì»¨ì„¤í„´íŠ¸", "ë¶„ì„", "ì¡°ì–¸"]
    }
    
    found_features = []
    text_lower = prompt_text.lower()
    
    for feature, keywords in keywords_analysis.items():
        if any(keyword.lower() in text_lower for keyword in keywords):
            found_features.append(feature)
    
    if found_features:
        return " â€¢ ".join(found_features[:3])  # ìµœëŒ€ 3ê°œ íŠ¹ì§•
    else:
        # fallback: ì²« ë¬¸ì¥ì—ì„œ ì˜ë¯¸ìˆëŠ” ë¶€ë¶„ ì¶”ì¶œ
        sentences = prompt_text.split('.')
        if sentences:
            first_sentence = sentences[0].strip()
            if len(first_sentence) > 10:
                return first_sentence[:80] + "..."
        return "ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸"

def render_prompt_selector():
    """ì§ê´€ì ì¸ í”„ë¡¬í”„íŠ¸ í¸ì§‘ UI"""
    
    # CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
    st.markdown("""
    <style>
        .prompt-info {
            background: #e3f2fd;
            color: #1565c0;
            padding: 0.25rem 0.5rem;
            border-radius: 12px;
            font-size: 0.7rem;
            margin: 0.25rem;
            display: inline-block;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # ê°œë³„ í”„ë¡¬í”„íŠ¸ í¸ì§‘ ì„¹ì…˜ë“¤
    render_individual_prompt_sections()

def render_individual_prompt_sections():
    """ê° í”„ë¡¬í”„íŠ¸ë¥¼ ê°œë³„ ì ‘ì´ì‹ ì„¹ì…˜ìœ¼ë¡œ í‘œì‹œ"""
    current_prompt = st.session_state.prompt_manager.get_prompt(st.session_state.active_prompt_name)
    
    if not current_prompt:
        st.error("í™œì„± í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    available_prompts = st.session_state.prompt_manager.get_prompt_list()
    
    # ì„¸ì…˜ ìƒíƒœì— ê°œë³„ í”„ë¡¬í”„íŠ¸ ì„ íƒ ì •ë³´ ì´ˆê¸°í™”
    if 'selected_analysis_prompt' not in st.session_state:
        st.session_state.selected_analysis_prompt = "default"
    if 'selected_response_prompt' not in st.session_state:
        st.session_state.selected_response_prompt = "default"
    
    # ì§ˆë¬¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì„¹ì…˜
    col_expander, col_selector = st.columns([3.5, 1])
    
    with col_expander:
        with st.expander(f"ğŸ” ì§ˆë¬¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ - {st.session_state.selected_analysis_prompt}", expanded=False):
            analysis_summary = extract_prompt_summary(current_prompt.get('query_analysis_prompt', ''))
            st.markdown(f'<div class="prompt-info">íŠ¹ì§•: {analysis_summary}</div>', unsafe_allow_html=True)
            st.caption(f"ğŸ“ {len(current_prompt.get('query_analysis_prompt', '')):,}ì")
            
            source_prompt_analysis = st.session_state.selected_analysis_prompt
            
            # í¸ì§‘ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì˜ì—­
            # ì„ íƒëœ í”„ë¡¬í”„íŠ¸ì—ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            if source_prompt_analysis:
                source_data = st.session_state.prompt_manager.get_prompt_by_type(source_prompt_analysis, "query_analysis")
                if source_data:
                    initial_analysis_content = source_data.get('content', '')
                else:
                    initial_analysis_content = current_prompt.get('query_analysis_prompt', '')
            else:
                initial_analysis_content = current_prompt.get('query_analysis_prompt', '')
            
            new_analysis_prompt = st.text_area(
                "ì§ˆë¬¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ í¸ì§‘",
                value=initial_analysis_content,
                height=300,
                key="edit_analysis_prompt",
                help="ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í”„ë¡¬í”„íŠ¸"
            )
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ’¾ ì €ì¥", key="save_analysis", use_container_width=True):
                    st.session_state.show_save_analysis_form = True
                    st.session_state.temp_analysis_content_for_save = new_analysis_prompt
                    st.rerun()
            
            # ì €ì¥ í¼ í‘œì‹œ
            if st.session_state.get('show_save_analysis_form', False):
                with st.form("save_analysis_form", clear_on_submit=True):
                    st.markdown("**ğŸ’¾ ì§ˆë¬¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì €ì¥**")
                    save_name = st.text_input(
                        "ì €ì¥í•  í”„ë¡¬í”„íŠ¸ ì´ë¦„",
                        value="",
                        placeholder="ì˜ˆ: advanced_analysis, custom_prompt_v1",
                        help="ìƒˆë¡œìš´ ì´ë¦„ìœ¼ë¡œ ì €ì¥í•˜ê±°ë‚˜ ê¸°ì¡´ ì´ë¦„ìœ¼ë¡œ ë®ì–´ì“°ê¸° (defaultëŠ” ë³´í˜¸ë¨)"
                    )
                    
                    col_save1, col_save2, col_save3 = st.columns(3)
                    with col_save1:
                        if st.form_submit_button("âœ… ì €ì¥ í™•ì¸", type="primary", use_container_width=True):
                            if save_name:
                                success = save_prompt_as_new(
                                    save_name, 
                                    st.session_state.temp_analysis_content_for_save,
                                    current_prompt.get('model_response_prompt', ''),
                                    'analysis'
                                )
                                if success:
                                    st.session_state.show_save_analysis_form = False
                                    if hasattr(st.session_state, 'temp_analysis_content_for_save'):
                                        del st.session_state.temp_analysis_content_for_save
                                    st.rerun()
                            else:
                                st.warning("í”„ë¡¬í”„íŠ¸ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    
                    with col_save2:
                        if st.form_submit_button("âŒ ì·¨ì†Œ", use_container_width=True):
                            st.session_state.show_save_analysis_form = False
                            if hasattr(st.session_state, 'temp_analysis_content_for_save'):
                                del st.session_state.temp_analysis_content_for_save
                            st.rerun()
            
            with col2:
                if st.button("âš¡ ì ìš©", key="temp_apply_analysis", use_container_width=True):
                    # ì„ì‹œë¡œ ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥í•˜ê³  ì—ì´ì „íŠ¸ ì¬êµ¬ì„±
                    st.session_state.temp_prompts = {
                        'analysis': new_analysis_prompt,
                        'response': current_prompt.get('model_response_prompt', '')
                    }
                    st.session_state.agent = None
                    st.success("âš¡ ì ìš©ë¨!")
                    st.rerun()
    
    with col_selector:
        # ë†’ì´ ë§ì¶¤ì„ ìœ„í•œ ë¹ˆ ê³µê°„ ì¶”ê°€
        st.write("")
        
        # í”„ë¡¬í”„íŠ¸ ì„ íƒ (ì§ˆë¬¸ ë¶„ì„ìš©)
        available_analysis_prompts = st.session_state.prompt_manager.get_prompt_list_by_type("query_analysis")
        
        if len(available_analysis_prompts) > 1:
            # í˜„ì¬ ì„ íƒëœ í”„ë¡¬í”„íŠ¸ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
            try:
                current_index = available_analysis_prompts.index(st.session_state.selected_analysis_prompt)
            except ValueError:
                current_index = 0
                st.session_state.selected_analysis_prompt = available_analysis_prompts[0]
            
            selected_analysis_prompt = st.selectbox(
                "í”„ë¡¬í”„íŠ¸ ì„ íƒ",
                options=available_analysis_prompts,
                index=current_index,
                key="analysis_prompt_selector",
                help="ì‚¬ìš©í•  ì§ˆë¬¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
                label_visibility="collapsed"
            )
            
            # ì„ íƒì´ ë³€ê²½ëœ ê²½ìš° ì—…ë°ì´íŠ¸
            if selected_analysis_prompt != st.session_state.selected_analysis_prompt:
                st.session_state.selected_analysis_prompt = selected_analysis_prompt
                # ì—ì´ì „íŠ¸ ì¬ì´ˆê¸°í™” í•„ìš”
                st.session_state.agent = None
                st.success(f"âœ… ì§ˆë¬¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ê°€ '{selected_analysis_prompt}'ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
        
    
    # ìµœì¢… ë‹µë³€ í”„ë¡¬í”„íŠ¸ ì„¹ì…˜
    col_expander2, col_selector2 = st.columns([3.5, 1])
    
    with col_expander2:
        with st.expander(f"ğŸ’¬ ìµœì¢… ë‹µë³€ í”„ë¡¬í”„íŠ¸ - {st.session_state.selected_response_prompt}", expanded=False):
            response_summary = extract_prompt_summary(current_prompt.get('model_response_prompt', ''))
            st.markdown(f'<div class="prompt-info">íŠ¹ì§•: {response_summary}</div>', unsafe_allow_html=True)
            st.caption(f"ğŸ“ {len(current_prompt.get('model_response_prompt', '')):,}ì")
            
            source_prompt_response = st.session_state.selected_response_prompt
            
            # í¸ì§‘ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì˜ì—­
            # ì„ íƒëœ í”„ë¡¬í”„íŠ¸ì—ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            if source_prompt_response:
                source_data = st.session_state.prompt_manager.get_prompt_by_type(source_prompt_response, "model_response")
                if source_data:
                    initial_response_content = source_data.get('content', '')
                else:
                    initial_response_content = current_prompt.get('model_response_prompt', '')
            else:
                initial_response_content = current_prompt.get('model_response_prompt', '')
                
            if hasattr(st.session_state, 'temp_response_content'):
                initial_response_content = st.session_state.temp_response_content
                del st.session_state.temp_response_content
            
            new_response_prompt = st.text_area(
                "ìµœì¢… ë‹µë³€ í”„ë¡¬í”„íŠ¸ í¸ì§‘",
                value=initial_response_content,
                height=300,
                key="edit_response_prompt",
                help="ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í”„ë¡¬í”„íŠ¸"
            )
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ’¾ ì €ì¥", key="save_response", use_container_width=True):
                    st.session_state.show_save_response_form = True
                    st.session_state.temp_response_content_for_save = new_response_prompt
                    st.rerun()
            
            # ì €ì¥ í¼ í‘œì‹œ
            if st.session_state.get('show_save_response_form', False):
                with st.form("save_response_form", clear_on_submit=True):
                    st.markdown("**ğŸ’¾ ìµœì¢… ë‹µë³€ í”„ë¡¬í”„íŠ¸ ì €ì¥**")
                    save_name = st.text_input(
                        "ì €ì¥í•  í”„ë¡¬í”„íŠ¸ ì´ë¦„",
                        value="",
                        placeholder="ì˜ˆ: advanced_response, custom_prompt_v1",
                        help="ìƒˆë¡œìš´ ì´ë¦„ìœ¼ë¡œ ì €ì¥í•˜ê±°ë‚˜ ê¸°ì¡´ ì´ë¦„ìœ¼ë¡œ ë®ì–´ì“°ê¸° (defaultëŠ” ë³´í˜¸ë¨)"
                    )
                    
                    col_save1, col_save2 = st.columns(2)
                    with col_save1:
                        if st.form_submit_button("âœ… ì €ì¥ í™•ì¸", type="primary", use_container_width=True):
                            if save_name:
                                success = save_prompt_as_new(
                                    save_name,
                                    current_prompt.get('query_analysis_prompt', ''),
                                    st.session_state.temp_response_content_for_save,
                                    'response'
                                )
                                if success:
                                    st.session_state.show_save_response_form = False
                                    if hasattr(st.session_state, 'temp_response_content_for_save'):
                                        del st.session_state.temp_response_content_for_save
                                    st.rerun()
                            else:
                                st.warning("í”„ë¡¬í”„íŠ¸ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    
                    with col_save2:
                        if st.form_submit_button("âŒ ì·¨ì†Œ", use_container_width=True):
                            st.session_state.show_save_response_form = False
                            if hasattr(st.session_state, 'temp_response_content_for_save'):
                                del st.session_state.temp_response_content_for_save
                            st.rerun()
            
            with col2:
                if st.button("âš¡ ì ìš©", key="temp_apply_response", use_container_width=True):
                    # ì„ì‹œë¡œ ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥í•˜ê³  ì—ì´ì „íŠ¸ ì¬êµ¬ì„±
                    current_analysis = st.session_state.temp_prompts.get('analysis') if hasattr(st.session_state, 'temp_prompts') else current_prompt.get('query_analysis_prompt', '')
                    st.session_state.temp_prompts = {
                        'analysis': current_analysis,
                        'response': new_response_prompt
                    }
                    st.session_state.agent = None
                    st.success("âš¡ ì ìš©ë¨!")
                    st.rerun()
    
    with col_selector2:
        # ë†’ì´ ë§ì¶¤ì„ ìœ„í•œ ë¹ˆ ê³µê°„ ì¶”ê°€
        st.write("")
        
        # í”„ë¡¬í”„íŠ¸ ì„ íƒ (ìµœì¢… ë‹µë³€ìš©)
        available_response_prompts = st.session_state.prompt_manager.get_prompt_list_by_type("model_response")
        
        if len(available_response_prompts) > 1:
            # í˜„ì¬ ì„ íƒëœ í”„ë¡¬í”„íŠ¸ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
            try:
                current_index = available_response_prompts.index(st.session_state.selected_response_prompt)
            except ValueError:
                current_index = 0
                st.session_state.selected_response_prompt = available_response_prompts[0]
            
            selected_response_prompt = st.selectbox(
                "í”„ë¡¬í”„íŠ¸ ì„ íƒ",
                options=available_response_prompts,
                index=current_index,
                key="response_prompt_selector",
                help="ì‚¬ìš©í•  ìµœì¢… ë‹µë³€ í”„ë¡¬í”„íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
                label_visibility="collapsed"
            )
            
            # ì„ íƒì´ ë³€ê²½ëœ ê²½ìš° ì—…ë°ì´íŠ¸
            if selected_response_prompt != st.session_state.selected_response_prompt:
                st.session_state.selected_response_prompt = selected_response_prompt
                # ì—ì´ì „íŠ¸ ì¬ì´ˆê¸°í™” í•„ìš”
                st.session_state.agent = None
                st.success(f"âœ… ìµœì¢… ë‹µë³€ í”„ë¡¬í”„íŠ¸ê°€ '{selected_response_prompt}'ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
        

def save_prompt_section(current_prompt, section_key, new_content):
    """í”„ë¡¬í”„íŠ¸ ì„¹ì…˜ ì €ì¥"""
    try:
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°ì´í„° ë³µì‚¬
        updated_data = current_prompt.copy()
        updated_data[section_key] = new_content
        
        # í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸
        result = st.session_state.prompt_manager.update_prompt(
            prompt_id=current_prompt['id'],
            name=current_prompt['name'],
            query_analysis_prompt=updated_data.get('query_analysis_prompt', ''),
            model_response_prompt=updated_data.get('model_response_prompt', '')
        )
        
        return result is not None
    except Exception as e:
        st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def save_prompt_as_new(new_name, analysis_content, response_content, section_type):
    """ìƒˆë¡œìš´ ì´ë¦„ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ì €ì¥ (íƒ€ì…ë³„ ë…ë¦½ ì €ì¥)"""
    try:
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë³´í˜¸ ë¡œì§
        if new_name == 'default':
            st.warning("âš ï¸ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ëŠ” ë®ì–´ì“¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë¦„ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
            return False
        
        # section_typeì— ë”°ë¼ í•´ë‹¹ íƒ€ì…ë§Œ ì €ì¥
        if section_type == 'analysis':
            # ì§ˆë¬¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ë§Œ ì €ì¥
            prompt_type = "query_analysis"
            content = analysis_content
            prompt_name = new_name  # suffix ì œê±°
        elif section_type == 'response':
            # ìµœì¢… ë‹µë³€ í”„ë¡¬í”„íŠ¸ë§Œ ì €ì¥
            prompt_type = "model_response"
            content = response_content
            prompt_name = new_name  # suffix ì œê±°
        else:
            st.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì„¹ì…˜ íƒ€ì…ì…ë‹ˆë‹¤.")
            return False
        
        # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
        existing_prompt = st.session_state.prompt_manager.get_prompt_by_type(prompt_name, prompt_type)
        
        if existing_prompt:
            # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸ í™•ì¸
            if st.session_state.get(f'confirm_overwrite_{section_type}', False):
                result = st.session_state.prompt_manager.update_prompt_by_type(
                    prompt_id=existing_prompt['id'],
                    name=prompt_name,
                    content=content,
                    prompt_type=prompt_type
                )
                
                if result:
                    st.success(f"âœ… '{new_name}' {section_type} í”„ë¡¬í”„íŠ¸ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.session_state[f'confirm_overwrite_{section_type}'] = False
                    return True
            else:
                st.warning(f"âš ï¸ '{new_name}' {section_type} í”„ë¡¬í”„íŠ¸ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ?")
                if st.button("ğŸ”„ ë®ì–´ì“°ê¸° í™•ì¸", key=f"confirm_overwrite_{new_name}_{section_type}"):
                    st.session_state[f'confirm_overwrite_{section_type}'] = True
                    st.rerun()
                return False
        else:
            # ìƒˆ í”„ë¡¬í”„íŠ¸ ìƒì„± (íƒ€ì…ë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ)
            result = st.session_state.prompt_manager.create_prompt_by_type(
                name=prompt_name,
                content=content,
                prompt_type=prompt_type
            )
            
            if result:
                st.success(f"âœ… '{new_name}' {section_type} í”„ë¡¬í”„íŠ¸ê°€ ìƒˆë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                return True
        
        return False
        
    except Exception as e:
        st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False




def main():
    """
    Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ì¸ ì§„ì…ì 
    
    ì´ í•¨ìˆ˜ëŠ” ì „ì²´ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ UIë¥¼ êµ¬ì„±í•˜ê³  ì‚¬ìš©ì ì¸í„°ë™ì…˜ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    ì±„íŒ… ì¸í„°í˜ì´ìŠ¤, ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ í‘œì‹œ, ìƒˆë¡œìš´ ë©”ì‹œì§€ ì²˜ë¦¬ ë“±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    
    ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ìµœì í™”:
    - ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì´ˆê¸°í™”
    - ì‚¬ìš©ì ì…ë ¥ ì‹œ ì¶”ê°€ ì´ˆê¸°í™” ë°©ì§€
    """
    # ì• í”Œë¦¬ì¼€ì´ì…˜ í—¤ë”
    st.title("ğŸ›ï¸ AI ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ (ê°„ë‹¨í•œ ìƒíƒœ í‘œì‹œ)
    # if st.session_state.agent is not None:
    #     st.success("ğŸ¤– ì—ì´ì „íŠ¸: **í™œì„±í™”**")
    # else:
    #     st.error("ğŸ¤– ì—ì´ì „íŠ¸: **ë¹„í™œì„±í™”**")
    
    # í”„ë¡¬í”„íŠ¸ ì„ íƒ ë° í¸ì§‘ UI
    # render_prompt_selector()

    st.markdown("---")
    st.markdown("### ğŸ’¬ ëŒ€í™”")
    st.markdown("ë¬´ì—‡ì„ ì°¾ì•„ë“œë¦´ê¹Œìš”? ì›í•˜ëŠ” ìƒí’ˆì— ëŒ€í•´ ìì„¸íˆ ì•Œë ¤ì£¼ì„¸ìš”.")

    # ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ)
    if st.session_state.agent is None:
        # ì´ˆê¸°í™” ì‹œë„
        initialization_success = asyncio.run(initialize_agent())
        if not initialization_success:
            st.warning("âš ï¸ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return  # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ë” ì´ìƒ ì§„í–‰í•˜ì§€ ì•ŠìŒ
        else:
            # ì´ˆê¸°í™” ì„±ê³µ ì‹œ UI ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ìƒíƒœ ë°˜ì˜
            st.rerun()

    # ì—ì´ì „íŠ¸ê°€ ì¤€ë¹„ëœ í›„ì—ë§Œ UI í‘œì‹œ
    if st.session_state.agent is not None:
        # ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
        display_conversation_history()
        
        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        handle_user_input()
    else:
        st.info("ğŸ”„ ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
        st.button("ğŸ”„ ë‹¤ì‹œ ì‹œë„", on_click=lambda: st.rerun())


def display_conversation_history():
    """
    ì´ì „ ëŒ€í™” ë‚´ìš©ì„ í™”ë©´ì— í‘œì‹œ
    
    ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ ìˆœíšŒí•˜ë©° ê° ë©”ì‹œì§€ë¥¼
    ì ì ˆí•œ í˜•íƒœë¡œ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "assistant" and message.get("parts"):
                # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ì˜ ê° íŒŒíŠ¸ë¥¼ ìˆœì„œëŒ€ë¡œ í‘œì‹œ
                for part in message["parts"]:
                    if part["type"] == "text":
                        st.markdown(part["data"])
                    elif part["type"] == "tool_call":
                        # ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ìƒíƒœ ì»´í¬ë„ŒíŠ¸ë¡œ í‘œì‹œ
                        call_data = part["data"]
                        status_text, status_state = determine_tool_status(call_data)

                        with st.status(f"ë„êµ¬ {status_text}: {call_data['name']}", 
                                     expanded=False, state=status_state):
                            render_tool_call(call_data)
            else:
                # ì‚¬ìš©ì ë©”ì‹œì§€ëŠ” ë‹¨ìˆœ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                st.markdown(message.get("content", ""))


def handle_user_input():
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±
    
    ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì…ë ¥í–ˆì„ ë•Œ í˜¸ì¶œë˜ë©°,
    ì—ì´ì „íŠ¸ì—ê²Œ ì§ˆì˜í•˜ê³  ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ í‘œì‹œí•©ë‹ˆë‹¤.
    
    ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸:
    - ì…ë ¥ ì²˜ë¦¬ ì „ ì—ì´ì „íŠ¸ ì¤€ë¹„ ìƒíƒœ ê²€ì¦
    - ì—ì´ì „íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    """
    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    if prompt := st.chat_input("ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        
        # ì—ì´ì „íŠ¸ ì¤€ë¹„ ìƒíƒœ í™•ì¸
        if not st.session_state.agent:
            st.error("âŒ ì—ì´ì „íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.")
            return
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.markdown(prompt)

        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì˜ì—­
        with st.chat_message("assistant"):
            message_container = st.container()
            
            try:
                # ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ ìƒì„±
                response_stream = get_response(
                    st.session_state.agent, 
                    prompt, 
                    st.session_state.history
                )
                
                # ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ ë° ë©”ì‹œì§€ íŒŒíŠ¸ ìˆ˜ì§‘
                message_parts = asyncio.run(stream_and_update_ui(response_stream, message_container))

                # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant",
                    "parts": message_parts
                })

                # LangChain íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
                assistant_summary = generate_history_summary(message_parts)
                st.session_state.history.append(("user", prompt))
                st.session_state.history.append(("assistant", assistant_summary))

            except Exception as e:
                st.error(f"âŒ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.info("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ UI ìƒíƒœ ì •ë¦¬
        st.rerun()


# =============================================================================
# ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
# =============================================================================

if __name__ == "__main__":
    main()